---
permalink: /
title: "About"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a postdoctoral research associate in the [School of Data Science and Society](https://datascience.unc.edu) at the [University of North Carolina at Chapel Hill](https://www.unc.edu) working with [Amarjit Budhiraja](https://abudhiraja.web.unc.edu). My research interests lie broadly in the intersections of **mathematics of generative machine learning,** **mathematical control theory,** and **Bayesian computation**.  

I will be joining the Department of Mathematics at Rutgers University as an Assistant Professor in Fall 2026.

I was previously a postdoctoral research associate between the [Division of Applied Mathematics](https://appliedmath.brown.edu) at [Brown University](https://www.brown.edu) and the [Department of Mathematics and Statistics](https://www.umass.edu/mathematics-statistics/) at [UMass Amherst](https://www.umass.edu) with [Paul Dupuis](https://appliedmath.brown.edu/people/paul-dupuis), [Markos Katsoulakis](https://people.math.umass.edu/~markos/), [Luc Rey-Bellet](https://people.math.umass.edu/~lr7q/).

<!-- My research interests lie broadly in the **mathematics of machine learning** for analyzing and developing novel **generative modeling** algorithms from the perspectives of **mathematical control theory** and **mean-field games**. Conversely, I also develop theoretically well-grounded methods in **rare event simulation for dynamical systems** and **sampling methods for Bayesian computation** using tools from generative machine learning.  -->

I earned my PhD in Computational Science and Engineering from MIT in 2022. My advisor was [Youssef Marzouk](https://aeroastro.mit.edu/people/youssef-m-marzouk/) who heads the [Uncertainty Quantification group](https://uqgroup.mit.edu). I earned my Master's degree in Aeronautics & Astronautics at MIT in 2017, and my Bachelor's degrees in Engineering Physics and Applied Mathematics at UC Berkeley in 2015. I was a [MIT School of Engineering 2019-2020 Mathworks Fellow](https://engineering.mit.edu/students/graduate-student-fellowships/mathworks-fellows/). I spent the summer of 2017 as a research intern at United Technologies Research Center (now Raytheon), where I worked with [Tuhin Sahai](https://tuhinsahai.github.io/) on novel queuing systems.

[![Tree Website](/images/tree_website.png)](/research/) 





<!-- ## NEW COURSE for Spring 2024! [Math 590STA: Intro to Mathematical Machine Learning](https://benjzhang.github.io/ma590sta/)
[<img align="right" width="300" src="https://benjzhang.github.io/files/ma590sta_poster.png" />](https://benjzhang.github.io/ma590sta/)
Join us for MATH 590STA, an introduction to mathematical machine learning! We will be covering classical solutions to machine learning tasks such as regression, classification, and dimension reduction from fundamental mathematical concepts. 
 -->

<!-- 
## Learning *Learning*
I am the co-organizer of the [Learning *Learning*](https://www.umass.edu/mathematics-statistics/seminars/learning-learning-seminar) seminar, along with [Hyemin Gu](https://hyemingu.github.io). This is an internal seminar at UMass Amherst where graduate students and postdocs discuss latest developments in machine learning and data science through reading groups and tutorials. It is also a venue for students to present their research. Please contact us if you wish to participate in the group!  -->


## Recent News

<!-- **October**
I will be speaking in the [Stochastic Analysis Seminar](https://orfe.princeton.edu/events/2025/benjamin-zhang-university-north-carolina-chapel-hill) in the Department of Operations Research and Financial Engineering at Princeton University.  -->

**February**

Our paper [Wasserstein proximal operators describe score-based generative models and resolve memorization](https://arxiv.org/abs/2402.06162) has been accepted to the *SIAM Journal on Mathematics of Data Science*!

**November**

New preprint on Knothe-Rosenblatt maps (triangular maps) and optimal transport: In [Knothe-Rosenblatt maps via soft-constrained optimal transport](https://arxiv.org/abs/2511.04579), we show that the KR map can be obtained as a limit of maps solving a relaxed optimal transport problem with a soft optimal transport constraint. Our results provide theoretical jusification for variational methods that estimate KR maps by minimizing a divergence and provides new methodological ideas for new ways of constructing these maps. This is joint work with [Ricardo Baptista](https://www.ricardobaptista.com), [Franca Hoffman](https://www.cms.caltech.edu/people/franca-hoffmann), and [Minh Nguyen](https://minhngvh.github.io).

**October**

New preprint on transformer architectures: In [Stability of Transformers under Layer Normalization](https://arxiv.org/abs/2510.09904), we study how layer normalization placement affects the stability of transformers, analyzing both the growth of hidden states and the backpropagation of gradients. Our theory explains when different placements lead to stable training and guides the scaling of residual connections for improved performance. This is joint work with [Kelvin Kan](https://www.math.emory.edu/~kkan5/), [Xingjian Li](https://oden.utexas.edu/people/directory/Xingjian-Li/), [Tuhin Sahai](https://tuhinsahai.github.io), [Stan Osher](https://www.math.ucla.edu/~sjo/), and [Markos Katsoulakis](https://people.math.umass.edu/~markos/).

<!-- **September**

Happy to announce that our paper [Optimal Control for Transformer Architectures: Enhancing Generalization, Robustness and Efficiency.](https://arxiv.org/abs/2505.13499) has been accepted to NeurIPS 2024 through the Main Track! 


New preprint on applications of generative modeling to operator learning! In [Probabilistic operator learning: generative modeling and uncertainty quantification for foundation models of differential equations](https://arxiv.org/abs/2509.05186), we place operator learning within the framework of probabilistic machine learning through a random differential equations formalism. We show that in-context operator learning (ICON) performs Bayesian inference implicitly and demonstrate how generative modeling provides uncertainty quantification for predictions made by ICON. This is joint work with [Siting Liu](https://sites.google.com/view/sitingl), [Stan Osher](https://www.math.ucla.edu/~sjo/), and [Markos Katsoulakis](https://people.math.umass.edu/~markos/).  -->


<!-- **August**

I have moved to the School of Data Science and Society at the University of North Carolina at Chapel Hill as a postdoctoral research associate.  -->

## Recent and upcoming events


**June**

Scientific Computing and Differential Equations (SciCADE 2026), June 29 - July 3, 2026. 

SIAM Conference on Optimization, June 2-5, 2026. 

**April**

Data Science and Statistics Seminar, Department of Mathematics, University of Tennessee, Knoxville. April 9, 2026. 

**March**

SIAM Conference on Uncertainty Quantification, March 22-25, 2026. 

[Computational and Applied Mathematics Seminar](https://math.asu.edu/node/10501), School of Mathematical and Statistical Sciences, Arizona State University, March 16, 2026.

Level Set Collective Seminar, Department of Mathematics, UCLA, March 9, 2026. 

<!-- **December**

[Virtual Analysis and PDE Seminar](https://sites.google.com/view/vapseminar/home), December 11, 2025. 

**November**

Colloquium, Department of Mathematics, Louisiana State University, November 20, 2025. 

[Special Colloquium](https://www.math.rutgers.edu/news-events/seminars-colloquia-calendar/eventdetail/23163/133/a-mean-field-games-laboratory-for-generative-artificial-intelligence-from-foundations-to-applications-in-scientific-computing), Department of Mathematics, Rutgers University, November 18, 2025.  -->

<!-- **July**

Our paper [Nonlinear denoising score matching for enhanced learning of structured distributions](https://www.sciencedirect.com/science/article/pii/S0045782525004980) has been accepted to *Computer Methods in Applied Mechanics and Engineering* in their special issues on [Generative Artificial Intelligence for Predictive Simulations and Decision-Making in Science and Engineering](https://www.sciencedirect.com/special-issue/109BSBSP137).  -->

<!-- 
**May** 

Three new preprints! 

In [Particle exchange Monte Carlo methods for eigenfunction and related nonlinear problems](https://arxiv.org/abs/2505.23456), we introduce a novel particle exchange Monte Carlo method that provide stochastic representations of eigenvalue problems related to generators of diffusion processes. We also discuss applications for approximating quasistationary distributions and ergodic stochastic control. This is joint work with [Paul Dupuis](https://appliedmath.brown.edu/people/paul-dupuis). 

In [Optimal control for Transformer architectures](https://arxiv.org/abs/2505.13499), we provide a framework for understanding transformer neural network architectures using tools from optimal control theory. We provide theoretical guarantees and numerical experiments showing how optimal control ideas can enhance generalization, robustness, and training efficiency of transformers. This is joint work with [Kelvin Kan](https://www.math.emory.edu/~kkan5/), [Xingjian Li](https://oden.utexas.edu/people/directory/Xingjian-Li/), [Tuhin Sahai](https://tuhinsahai.github.io), [Stan Osher](https://www.math.ucla.edu/~sjo/), and [Markos Katsoulakis](https://people.math.umass.edu/~markos/). 

In [Proximal optimal transport divergences](https://arxiv.org/abs/2505.12097), we introduce a new class of probability divergences based on the infimal convolution of divergences and optimal transport distances, including Wasserstein distances. These distances inherits the desirable properties of information divergences and transport distances, and we discuss how they are frequently unknowingly employed in generative modeling. This is joint work with [Panagiota Birmpa](https://sites.google.com/site/panagiotabirmpa/home), [Ricardo Baptista](https://www.ricardobaptista.com), [Markos Katsoulakis](https://people.math.umass.edu/~markos/), and [Luc Rey-Bellet](https://people.math.umass.edu/~lr7q/). 

 -->
<!-- ## Upcoming Events

**July**

I will be attending and presenting in the [IPAM Workshop on Sampling, Inference, and Data-Driven Physical Modeling in Scientific Machine Learning](https://www.ipam.ucla.edu/programs/workshops/sampling-inference-and-data-driven-physical-modeling-in-scientific-machine-learning/). 
 -->

<!-- **June**
I am presenting a talk in the Advanced Concepts Office at NASA Marshall Space Flight Center.  -->

<!-- **May**
I will be attending and presenting in the [SIAM Conference on Applications of Dynamical Systems](https://www.siam.org/conferences-events/siam-conferences/ds25/) in the minisymposium on [Collective Dynamics in Multi-Agent Systems: Advances in Learning and Optimization](https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=82752). I will be presenting work on mean-field games and generative modeling. 


**March**
I am attending and presenting in the [SIAM Conference on Computational Science and Engineering](https://www.siam.org/conferences-events/past-event-archive/cse25) in the minisymposium on [Addressing intractability in optimal control](https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=81111). I am presenting recent ongoing work on ergodic control through interacting particle systems and generative modeling tools.  -->

<!-- 
**January**

I will be attending and presenting in the [IPAM Workshop on Sampling, Inference, and Data-Driven Physical Modeling in Scientific Machine Learning](https://www.ipam.ucla.edu/programs/workshops/sampling-inference-and-data-driven-physical-modeling-in-scientific-machine-learning/) from January 13-17, 2025 .

I am excited to be co-organizing the SIAM Minisymposium on Mathematical Perspectives on Generative modeling at the Joint Mathematics Meeting in Seattle, WA from January 8-11, 2025. This minisymposium is co-organized with [Jimmie Adriazola](https://search.asu.edu/profile/5123395)! [Session1](https://meetings.ams.org/math/jmm2025/meetingapp.cgi/Session/11412), [Session 2](https://meetings.ams.org/math/jmm2025/meetingapp.cgi/Session/11425).

**December**

I will be giving a colloquium talk in the [Department of Applied and Computational Mathematics and Statistics at the University of Notre Dame](https://acms.nd.edu) on December 9.

I will be giving a [colloquium](https://events.rice.edu/event/384273-cmor-colloquium-series-benjamin-zhang-brown) talk in the [Department of Computational Applied Mathematics and Operations Research at Rice University](https://cmor.rice.edu) on December 2. 

**November**

I will be attending the NITMB workshop on [Random Dynamical Systems, with Applications in Biology](https://www.nitmb.org/random-dynamical-systems) from November 4-8, where I will be giving an overview talk on applied stochastic differential equations. -->
    
<!-- **October** 
    
* I am organizing a minisymposium at the [SIAM Conference on Mathematics of Data Science 2024](https://www.siam.org/conferences-events/siam-conferences/mds24/) titled [Foundations of structure-exploiting flow-based generative models](https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=80601). I will also be presenting in the [Optimization algorithms for mean-field games and applications in data science](https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=80516) minisymposium where I will be presenting on our ongoing program relating mean-field games with generative modeling. I will also be presenting the associated poster in the [Tuesday poster session](https://meetings.siam.org/sess/dsp_talk.cfm?p=139931).  -->






[News archive](https://benjzhang.github.io/news)


<!-- 
## [APMA 1930Z: Introduction to Mathematical Machine Learning (Fall 2024)](https://benjzhang.github.io/apma1930z/)
[<img align="right" width="300" src="https://benjzhang.github.io/files/ma590sta_poster.png" />](https://benjzhang.github.io/apma1930z/)
I will be co-teaching APMA 1930Z at Brown University in Fall 2024. APMA 1930Z is the second iteration of [Math 590STA, first offered at UMass Amherst in Spring 2024](https://benjzhang.github.io/ma590sta/). We cover classical solutions to machine learning tasks such as regression, classification, and dimension reduction from fundamental mathematical concepts. 
 -->


<!-- **February**:

I am excited to announce our new preprint title [Wasserstein proximal operators describe score-based generative models and resolve memorization](https://arxiv.org/abs/2402.06162). We show that score-based generative models can be fundamentally understood as the Wasserstein proximal operator of cross-entropy and we build informed models that resolve the memorization phenomenon in SGMs. This is joint work with [Siting Liu](https://sites.google.com/view/siting6ucla/home), [Wuchen Li](https://people.math.sc.edu/wuchen/), [Markos Katsoulakis](https://people.math.umass.edu/~markos/), and [Stan Osher](https://www.math.ucla.edu/~sjo/).  -->





<!-- 

**November**
I will be giving a talk at [NYU Shanghai](https://dail.shanghai.nyu.edu/events/mean-field-games-laboratory-generative-modeling) on our recent work *Mean-Field Games Laboratory for Generative Modeling.*


**October**: 
I will be visiting [Emory University](http://www.math.emory.edu/site/codes/) and speaking in their [Computational and data-enabled science seminar series](http://www.math.emory.edu/site/codes/schedule/). 


I gave a talk on our work *Mean-Field Games Laboratory for Generative Modeling* to the [Machine Learning and Mean Field Games Seminar series](https://sites.google.com/view/mlmfgseminar/home) -->

<!-- **June**: I gave a talk on our work *Mean-Field Games Laboratory for Generative Modeling* to the UCLA Level Set Collective.  -->



<!-- **April**: Excited to announce our new preprint titled [A Mean-Field Games Laboratory for Generative Modeling](https://arxiv.org/abs/2304.13534). This joint work with Markos Katsoulakis. We show that flow and diffusion-based generative models, including normalizing flows, score-based models, and Wasserstein gradient flows can be derived from a single unifying mean-field games framework.  -->

<!-- **February**: I am the creator and organizer of the [Learning Learning](https://www.umass.edu/mathematics-statistics/seminars/learning-learning-seminar). This is a seminar for students and postdocs to present their in-progress research, and practice giving research presentations.  -->




<!--  Presenting a poster on our _Sampling via Controlled SDEs_ work at the [ICBINB workshop at NeurIPS2021](https://i-cant-believe-its-not-better.github.io/neurips2021/), December 13. 
 -->
<!-- This is the front page of a website that is powered by the [academicpages template](https://github.com/academicpages/academicpages.github.io) and hosted on GitHub pages. [GitHub pages](https://pages.github.com) is a free service in which websites are built and hosted from code and data stored in a GitHub repository, automatically updating when a new commit is made to the respository. This template was forked from the [Minimal Mistakes Jekyll Theme](https://mmistakes.github.io/minimal-mistakes/) created by Michael Rose, and then extended to support the kinds of content that academics have: publications, talks, teaching, a portfolio, blog posts, and a dynamically-generated CV. You can fork [this repository](https://github.com/academicpages/academicpages.github.io) right now, modify the configuration and markdown files, add your own PDFs and other content, and have your own site for free, with no ads! An older version of this template powers my own personal website at [stuartgeiger.com](http://stuartgeiger.com), which uses [this Github repository](https://github.com/staeiou/staeiou.github.io).
 -->
<!-- A data-driven personal website
======
Like many other Jekyll-based GitHub Pages templates, academicpages makes you separate the website's content from its form. The content & metadata of your website are in structured markdown files, while various other files constitute the theme, specifying how to transform that content & metadata into HTML pages. You keep these various markdown (.md), YAML (.yml), HTML, and CSS files in a public GitHub repository. Each time you commit and push an update to the repository, the [GitHub pages](https://pages.github.com/) service creates static HTML pages based on these files, which are hosted on GitHub's servers free of charge.

Many of the features of dynamic content management systems (like Wordpress) can be achieved in this fashion, using a fraction of the computational resources and with far less vulnerability to hacking and DDoSing. You can also modify the theme to your heart's content without touching the content of your site. If you get to a point where you've broken something in Jekyll/HTML/CSS beyond repair, your markdown files describing your talks, publications, etc. are safe. You can rollback the changes or even delete the repository and start over -- just be sure to save the markdown files! Finally, you can also write scripts that process the structured data on the site, such as [this one](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb) that analyzes metadata in pages about talks to display [a map of every location you've given a talk](https://academicpages.github.io/talkmap.html).

Getting started
======
1. Register a GitHub account if you don't have one and confirm your e-mail (required!)
1. Fork [this repository](https://github.com/academicpages/academicpages.github.io) by clicking the "fork" button in the top right. 
1. Go to the repository's settings (rightmost item in the tabs that start with "Code", should be below "Unwatch"). Rename the repository "[your GitHub username].github.io", which will also be your website's URL.
1. Set site-wide configuration and create content & metadata (see below -- also see [this set of diffs](http://archive.is/3TPas) showing what files were changed to set up [an example site](https://getorg-testacct.github.io) for a user with the username "getorg-testacct")
1. Upload any files (like PDFs, .zip files, etc.) to the files/ directory. They will appear at https://[your GitHub username].github.io/files/example.pdf.  
1. Check status by going to the repository settings, in the "GitHub pages" section

Site-wide configuration
------
The main configuration file for the site is in the base directory in [_config.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_config.yml), which defines the content in the sidebars and other site-wide features. You will need to replace the default variables with ones about yourself and your site's github repository. The configuration file for the top menu is in [_data/navigation.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_data/navigation.yml). For example, if you don't have a portfolio or blog posts, you can remove those items from that navigation.yml file to remove them from the header. 

Create content & metadata
------
For site content, there is one markdown file for each type of content, which are stored in directories like _publications, _talks, _posts, _teaching, or _pages. For example, each talk is a markdown file in the [_talks directory](https://github.com/academicpages/academicpages.github.io/tree/master/_talks). At the top of each markdown file is structured data in YAML about the talk, which the theme will parse to do lots of cool stuff. The same structured data about a talk is used to generate the list of talks on the [Talks page](https://academicpages.github.io/talks), each [individual page](https://academicpages.github.io/talks/2012-03-01-talk-1) for specific talks, the talks section for the [CV page](https://academicpages.github.io/cv), and the [map of places you've given a talk](https://academicpages.github.io/talkmap.html) (if you run this [python file](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.py) or [Jupyter notebook](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb), which creates the HTML for the map based on the contents of the _talks directory).

**Markdown generator**

I have also created [a set of Jupyter notebooks](https://github.com/academicpages/academicpages.github.io/tree/master/markdown_generator
) that converts a CSV containing structured data about talks or presentations into individual markdown files that will be properly formatted for the academicpages template. The sample CSVs in that directory are the ones I used to create my own personal website at stuartgeiger.com. My usual workflow is that I keep a spreadsheet of my publications and talks, then run the code in these notebooks to generate the markdown files, then commit and push them to the GitHub repository.

How to edit your site's GitHub repository
------
Many people use a git client to create files on their local computer and then push them to GitHub's servers. If you are not familiar with git, you can directly edit these configuration and markdown files directly in the github.com interface. Navigate to a file (like [this one](https://github.com/academicpages/academicpages.github.io/blob/master/_talks/2012-03-01-talk-1.md) and click the pencil icon in the top right of the content preview (to the right of the "Raw | Blame | History" buttons). You can delete a file by clicking the trashcan icon to the right of the pencil icon. You can also create new files or upload files by navigating to a directory and clicking the "Create new file" or "Upload files" buttons. 

Example: editing a markdown file for a talk
![Editing a markdown file for a talk](/images/editing-talk.png)

For more info
------
More info about configuring academicpages can be found in [the guide](https://academicpages.github.io/markdown/). The [guides for the Minimal Mistakes theme](https://mmistakes.github.io/minimal-mistakes/docs/configuration/) (which this theme was forked from) might also be helpful.
 -->